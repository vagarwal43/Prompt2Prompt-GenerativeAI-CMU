{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "23529ad9ad598aac",
            "metadata": {
                "id": "23529ad9ad598aac"
            },
            "source": [
                "# Prompt-to-Prompt with Latent Diffusion"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "EGVDj9fLXQf_",
            "metadata": {
                "id": "EGVDj9fLXQf_"
            },
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "%cd /content/drive/MyDrive/path_to_your_project\n",
                "!pwd"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "w_0LaYbqXhma",
            "metadata": {
                "id": "w_0LaYbqXhma"
            },
            "outputs": [],
            "source": [
                "!pip install -r requirements.txt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "82be42f9d9cbdb20",
            "metadata": {
                "id": "82be42f9d9cbdb20"
            },
            "outputs": [],
            "source": [
                "# Clear VRAM if needed\n",
                "import gc\n",
                "import torch\n",
                "torch.cuda.empty_cache()\n",
                "gc.collect()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "nqXDpJPSbIVq",
            "metadata": {
                "id": "nqXDpJPSbIVq"
            },
            "source": [
                "# Baseline: Different Initial Noise for Each Prompt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "atKoClTjbgYd",
            "metadata": {
                "id": "atKoClTjbgYd"
            },
            "outputs": [],
            "source": [
                "from prompt2prompt import MyLDMPipeline, MySharedAttentionSwapper, unet_inject_attention_modules, create_image_grid\n",
                "\n",
                "prompt = [\n",
                "        \"A painting of a squirrel eating a burger\",\n",
                "        \"A painting of a cat eating a burger\",\n",
                "        \"A painting of a lion eating a burger\",\n",
                "        \"A painting of a deer eating a burger\",\n",
                "    ]\n",
                "\n",
                "num_inference_steps = 50\n",
                "guidance_scale = 7.5\n",
                "on_colab = True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5K9RlaO_aHzX",
            "metadata": {
                "id": "5K9RlaO_aHzX"
            },
            "outputs": [],
            "source": [
                "pipe = MyLDMPipeline(num_inference_steps, guidance_scale)\n",
                "swapper = MySharedAttentionSwapper(prompt, pipe.tokenizer, prop_steps_cross=0.0, prop_steps_self=0.0)\n",
                "unet_inject_attention_modules(pipe.unet, swapper)\n",
                "image = pipe._generate_image_from_text(prompt, pipe.vae, pipe.tokenizer, pipe.text_encoder, pipe.unet, pipe.scheduler, pipe.feature_extractor, pipe.safety_checker, swapper, pipe.num_inference_steps, pipe.guidance_scale, False)\n",
                "grid_image = create_image_grid(image)\n",
                "if on_colab:\n",
                "    display(grid_image)\n",
                "else:\n",
                "    grid_image.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "v5HsLQxabMjw",
            "metadata": {
                "id": "v5HsLQxabMjw"
            },
            "source": [
                "# Same Initial Noise for Each Prompt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dle3AwhJZ1Cj",
            "metadata": {
                "id": "dle3AwhJZ1Cj"
            },
            "outputs": [],
            "source": [
                "pipe = MyLDMPipeline(num_inference_steps, guidance_scale)\n",
                "swapper = MySharedAttentionSwapper(prompt, pipe.tokenizer, prop_steps_cross=0.0, prop_steps_self=0.0)\n",
                "unet_inject_attention_modules(pipe.unet, swapper)\n",
                "image = pipe.generate_image_from_text(prompt, swapper)\n",
                "grid_image = create_image_grid(image)\n",
                "if on_colab:\n",
                "    display(grid_image)\n",
                "else:\n",
                "    grid_image.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "y_G_EdOibRz3",
            "metadata": {
                "id": "y_G_EdOibRz3"
            },
            "source": [
                "# Prompt-to-Prompt: Word Swap"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9eQyX88OY3aP",
            "metadata": {
                "id": "9eQyX88OY3aP"
            },
            "outputs": [],
            "source": [
                "pipe = MyLDMPipeline(num_inference_steps, guidance_scale)\n",
                "swapper = MySharedAttentionSwapper(prompt, pipe.tokenizer, prop_steps_cross=0.8, prop_steps_self=0.2)\n",
                "unet_inject_attention_modules(pipe.unet, swapper)\n",
                "image = pipe.generate_image_from_text(prompt, swapper)\n",
                "grid_image = create_image_grid(image)\n",
                "if on_colab:\n",
                "    display(grid_image)\n",
                "else:\n",
                "    grid_image.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "BSMKa3FZcEY2",
            "metadata": {
                "id": "BSMKa3FZcEY2"
            },
            "source": [
                "# Prompt-to-Prompt: Modify Cross-Attention Injection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1fugGXahcF0T",
            "metadata": {
                "id": "1fugGXahcF0T"
            },
            "outputs": [],
            "source": [
                "prompt = [\"A painting of a squirrel eating a burger\",\n",
                "           \"A painting of a dog eating a burger\",\n",
                "          ]\n",
                "\n",
                "pipe = MyLDMPipeline(num_inference_steps, guidance_scale)\n",
                "swapper = MySharedAttentionSwapper(prompt, pipe.tokenizer, prop_steps_cross=0.1, prop_steps_self=0.2)\n",
                "unet_inject_attention_modules(pipe.unet, swapper)\n",
                "image = pipe.generate_image_from_text(prompt, swapper)\n",
                "grid_image = create_image_grid(image)\n",
                "if on_colab:\n",
                "    display(grid_image)\n",
                "else:\n",
                "    grid_image.show()\n",
                "\n",
                "pipe = MyLDMPipeline(num_inference_steps, guidance_scale)\n",
                "swapper = MySharedAttentionSwapper(prompt, pipe.tokenizer, prop_steps_cross=0.5, prop_steps_self=0.2)\n",
                "unet_inject_attention_modules(pipe.unet, swapper)\n",
                "image = pipe.generate_image_from_text(prompt, swapper)\n",
                "grid_image = create_image_grid(image)\n",
                "if on_colab:\n",
                "    display(grid_image)\n",
                "else:\n",
                "    grid_image.show()\n",
                "\n",
                "pipe = MyLDMPipeline(num_inference_steps, guidance_scale)\n",
                "swapper = MySharedAttentionSwapper(prompt, pipe.tokenizer, prop_steps_cross=0.9, prop_steps_self=0.2)\n",
                "unet_inject_attention_modules(pipe.unet, swapper)\n",
                "image = pipe.generate_image_from_text(prompt, swapper)\n",
                "grid_image = create_image_grid(image)\n",
                "if on_colab:\n",
                "    display(grid_image)\n",
                "else:\n",
                "    grid_image.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "mh-unxTmdsy9",
            "metadata": {
                "id": "mh-unxTmdsy9"
            },
            "source": [
                "# Prompt-to-Prompt: Modify Self-Attention Injection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "g4mdqjQwdyAP",
            "metadata": {
                "id": "g4mdqjQwdyAP"
            },
            "outputs": [],
            "source": [
                "prompt = [\"A painting of a squirrel eating a burger\",\n",
                "           \"A painting of a dog eating a burger\",\n",
                "          ]\n",
                "\n",
                "pipe = MyLDMPipeline(num_inference_steps, guidance_scale)\n",
                "swapper = MySharedAttentionSwapper(prompt, pipe.tokenizer, prop_steps_cross=0.5, prop_steps_self=0.1)\n",
                "unet_inject_attention_modules(pipe.unet, swapper)\n",
                "image = pipe.generate_image_from_text(prompt, swapper)\n",
                "grid_image = create_image_grid(image)\n",
                "if on_colab:\n",
                "    display(grid_image)\n",
                "else:\n",
                "    grid_image.show()\n",
                "\n",
                "pipe = MyLDMPipeline(num_inference_steps, guidance_scale)\n",
                "swapper = MySharedAttentionSwapper(prompt, pipe.tokenizer, prop_steps_cross=0.5, prop_steps_self=0.5)\n",
                "unet_inject_attention_modules(pipe.unet, swapper)\n",
                "image = pipe.generate_image_from_text(prompt, swapper)\n",
                "grid_image = create_image_grid(image)\n",
                "if on_colab:\n",
                "    display(grid_image)\n",
                "else:\n",
                "    grid_image.show()\n",
                "\n",
                "pipe = MyLDMPipeline(num_inference_steps, guidance_scale)\n",
                "swapper = MySharedAttentionSwapper(prompt, pipe.tokenizer, prop_steps_cross=0.5, prop_steps_self=0.9)\n",
                "unet_inject_attention_modules(pipe.unet, swapper)\n",
                "image = pipe.generate_image_from_text(prompt, swapper)\n",
                "grid_image = create_image_grid(image)\n",
                "if on_colab:\n",
                "    display(grid_image)\n",
                "else:\n",
                "    grid_image.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "nBXsjuGHebDL",
            "metadata": {
                "id": "nBXsjuGHebDL"
            },
            "source": [
                "# Prompt-to-Prompt: Single-Token to Multiple-Token Word Swap"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "z9GskTBlEdZI",
            "metadata": {
                "id": "z9GskTBlEdZI"
            },
            "outputs": [],
            "source": [
                "# Show the output of get_replacement_mapper_ on a small example\n",
                "from prompt2prompt import get_replacement_mapper_\n",
                "pipe = MyLDMPipeline(num_inference_steps, guidance_scale)\n",
                "tokenizer = pipe.tokenizer\n",
                "x = 'lion'\n",
                "y = 'hippopotamus'\n",
                "print(tokenizer.encode(x))\n",
                "print(tokenizer.encode(y))\n",
                "print(get_replacement_mapper_(x, y, tokenizer)[:5,:5])\n",
                "print(get_replacement_mapper_(y, x, tokenizer)[:5,:5])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "CV0-txjre7ft",
            "metadata": {
                "id": "CV0-txjre7ft"
            },
            "outputs": [],
            "source": [
                "prompt = [\"A photograph of a lion eating a cake\",\n",
                "          \"A photograph of a hippopotamus eating a cake\",\n",
                "          ]\n",
                "pipe = MyLDMPipeline(num_inference_steps, guidance_scale)\n",
                "swapper = MySharedAttentionSwapper(prompt, pipe.tokenizer, prop_steps_cross=0.8, prop_steps_self=0.2)\n",
                "unet_inject_attention_modules(pipe.unet, swapper)\n",
                "image = pipe.generate_image_from_text(prompt, swapper)\n",
                "grid_image = create_image_grid(image)\n",
                "if on_colab:\n",
                "    display(grid_image)\n",
                "else:\n",
                "    grid_image.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "Q_kbv7X_fda6",
            "metadata": {
                "id": "Q_kbv7X_fda6"
            },
            "source": [
                "# Prompt-to-Prompt: Multiple-Token to Single-Token Word Swap"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2dZ1ioaSffY9",
            "metadata": {
                "id": "2dZ1ioaSffY9"
            },
            "outputs": [],
            "source": [
                "prompt = [\"A photograph of a hippopotamus eating a cake\",\n",
                "          \"A photograph of a lion eating a cake\",\n",
                "          ]\n",
                "pipe = MyLDMPipeline(num_inference_steps, guidance_scale)\n",
                "swapper = MySharedAttentionSwapper(prompt, pipe.tokenizer, prop_steps_cross=0.8, prop_steps_self=0.2)\n",
                "unet_inject_attention_modules(pipe.unet, swapper)\n",
                "image = pipe.generate_image_from_text(prompt, swapper)\n",
                "grid_image = create_image_grid(image)\n",
                "if on_colab:\n",
                "    display(grid_image)\n",
                "else:\n",
                "    grid_image.show()"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 2
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython2",
            "version": "2.7.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}